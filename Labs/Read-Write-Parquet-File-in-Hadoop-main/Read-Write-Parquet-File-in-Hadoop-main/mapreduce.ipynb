{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/16 15:48:36 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/16 15:48:37 WARN spark.SparkContext: Please ensure that the number of slots available on your executors is limited by the number of cores to task cpus and not another custom resource. If cores is not the limiting resource then dynamic allocation will not work properly!\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder \\\n",
    "    .master('spark://172.12.0.2:7077') \\\n",
    "    .config(\"spark.driver.memory\", \"6g\")\\\n",
    "    .config('spark.cores.max', '4')\\\n",
    "    .appName('myapp1') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "# code run spark job to load parquetfile in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#read parquet file in HDFS. \n",
    "parquetFileDF = spark.read.parquet(\"/user/input/dataset_parquet/part.0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+--------------------+-------------+----------------+--------------------+------------+-------+\n",
      "|  id|composer|         composition|            movement|     ensemble|          source|         transcriber|catalog_name|seconds|\n",
      "+----+--------+--------------------+--------------------+-------------+----------------+--------------------+------------+-------+\n",
      "|1727|Schubert|Piano Quintet in ...|          2. Andante|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    447|\n",
      "|1728|Schubert|Piano Quintet in ...|  3. Scherzo: Presto|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    251|\n",
      "|1729|Schubert|Piano Quintet in ...|4. Andantino - Al...|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    444|\n",
      "|1730|Schubert|Piano Quintet in ...|   5. Allegro giusto|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    368|\n",
      "|1733|Schubert|Piano Sonata in A...|        2. Andantino|   Solo Piano|        Museopen|   Segundo G. Yogore|        D959|    546|\n",
      "|1734|Schubert|Piano Sonata in A...|3. Scherzo. Alleg...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D959|    325|\n",
      "|1735|Schubert|Piano Sonata in A...|4. Rondo. Allegretto|   Solo Piano|        Museopen|   Segundo G. Yogore|        D959|    714|\n",
      "|1739|Schubert|Piano Trio in B-f...|4. Rondo. Allegro...|   Piano Trio|European Archive|        harfesoft.de|        OP99|    490|\n",
      "|1742|Schubert|String Quintet in...|           2. Adagio|Viola Quintet|European Archive|        harfesoft.de|       OP163|    924|\n",
      "|1749|Schubert|Piano Sonata in A...|         1. Moderato|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    696|\n",
      "|1750|Schubert|Piano Sonata in A...|2. Andante poco m...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    784|\n",
      "|1751|Schubert|Piano Sonata in A...|3. Scherzo. Alleg...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    475|\n",
      "|1752|Schubert|Piano Sonata in A...|4. Rondo. Allegro...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    362|\n",
      "|1755|Schubert|Piano Sonata in A...|          2. Andante|   Solo Piano|        Museopen|   Segundo G. Yogore|        D784|    229|\n",
      "|1756|Schubert|Piano Sonata in A...|   3. Allegro vivace|   Solo Piano|        Museopen|   Segundo G. Yogore|        D784|    371|\n",
      "|1757|Schubert|Piano Sonata in C...|          1. Allegro|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    710|\n",
      "|1758|Schubert|Piano Sonata in C...|           2. Adagio|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    468|\n",
      "|1759|Schubert|Piano Sonata in C...|3. Menuetto and Trio|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    194|\n",
      "|1760|Schubert|Piano Sonata in C...|          4. Allegro|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    655|\n",
      "|1763|Schubert|        4 Impromptus|1. Impromptu in F...|   Solo Piano|Charlie Albright|  Jeruen Espino Dery|       OP142|    600|\n",
      "+----+--------+--------------------+--------------------+-------------+----------------+--------------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# show data from parquet file\n",
    "parquetFileDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  composer  value\n",
      "0      164      Bach    1.0\n",
      "1      129      Bach    1.0\n",
      "2      130      Bach    1.0\n",
      "3      131      Bach    1.0\n",
      "4      132      Bach    1.0\n",
      "..     ...       ...    ...\n",
      "325     27  Schubert    1.0\n",
      "326     28  Schubert    1.0\n",
      "327     29  Schubert    1.0\n",
      "328     15  Schubert    1.0\n",
      "329      0  Schubert    1.0\n",
      "\n",
      "[330 rows x 3 columns]\n",
      "[['Bach' 67.0]\n",
      " ['Beethoven' 157.0]\n",
      " ['Brahms' 24.0]\n",
      " ['Cambini' 9.0]\n",
      " ['Dvorak' 8.0]\n",
      " ['Faure' 4.0]\n",
      " ['Haydn' 3.0]\n",
      " ['Mozart' 24.0]\n",
      " ['Ravel' 4.0]\n",
      " ['Schubert' 30.0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# function map : tạo lên 1 cặp key - value: key = 1, value = composer\n",
    "def map(parquetFileDF):\n",
    "    df=parquetFileDF.toPandas()\n",
    "    map_data = pd.DataFrame()\n",
    "    for line in range(df.count()[0]):\n",
    "        map_data.at[line,'composer'] = df.at[line,'composer']\n",
    "        map_data.at[line,'value'] = 1\n",
    "    return map_data\n",
    "    \n",
    "def reducer(mapdata):\n",
    "    current_composer = None\n",
    "    current_count = 0\n",
    "    composer = None\n",
    "    df_output = pd.DataFrame()\n",
    "    line=None\n",
    "    for line in range(mapdata.count()[0]):\n",
    "        composer = mapdata.at[line,'composer']\n",
    "        count = mapdata.at[line,'value']\n",
    "        try:\n",
    "            count = int(count)\n",
    "        except ValueError:\n",
    "            # count was not a number, so silently\n",
    "            # ignore/discard this line\n",
    "            continue\n",
    "        if current_composer == composer:\n",
    "            current_count += count\n",
    "        else:\n",
    "            if current_composer:\n",
    "                df_output.at[line,'composer'] = current_composer\n",
    "                df_output.at[line,'count'] = current_count\n",
    "            current_count = count\n",
    "            current_composer = composer\n",
    "\n",
    "    if current_composer == composer:\n",
    "        df_output.at[line+1,'composer'] = current_composer\n",
    "        df_output.at[line+1,'count'] = current_count\n",
    "    return df_output\n",
    "\n",
    "mapdata_ = map(parquetFileDF)\n",
    "mapdata_ = mapdata_.sort_values(by='composer', ascending=True).reset_index()\n",
    "print(mapdata_)\n",
    "output = reducer(mapdata_)\n",
    "print(output.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| composer|count|\n",
      "+---------+-----+\n",
      "|    Faure|  4.0|\n",
      "|    Haydn|  3.0|\n",
      "|   Mozart| 24.0|\n",
      "|    Ravel|  4.0|\n",
      "| Schubert| 30.0|\n",
      "|     Bach| 67.0|\n",
      "|Beethoven|157.0|\n",
      "|   Brahms| 24.0|\n",
      "|  Cambini|  9.0|\n",
      "|   Dvorak|  8.0|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(output.astype(str))\n",
    "df1.write.parquet(\"/user/output/output.parquet\")\n",
    "# read output\n",
    "output = spark.read.parquet(\"/user/output/output.parquet\")\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
